{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czkCSFjRPjLs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLrAdN2lS8aE",
        "outputId": "b48519aa-a132-43b9-f7f5-0244efff48e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWe0W7BiPjLu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from scikeras import wrappers\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import losses\n",
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import time\n",
        "from pickle import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brdW1EuhPjLv"
      },
      "outputs": [],
      "source": [
        "attack_types = {\n",
        "        'normal': 'normal',\n",
        "\n",
        "        'back': 'DoS',\n",
        "        'land': 'DoS',\n",
        "        'neptune': 'DoS',\n",
        "        'pod': 'DoS',\n",
        "        'smurf': 'DoS',\n",
        "        'teardrop': 'DoS',\n",
        "        'mailbomb': 'DoS',\n",
        "        'apache2': 'DoS',\n",
        "        'processtable': 'DoS',\n",
        "        'udpstorm': 'DoS',\n",
        "\n",
        "        'ipsweep': 'Probe',\n",
        "        'nmap': 'Probe',\n",
        "        'portsweep': 'Probe',\n",
        "        'satan': 'Probe',\n",
        "        'mscan': 'Probe',\n",
        "        'saint': 'Probe',\n",
        "\n",
        "        'ftp_write': 'R2L',\n",
        "        'guess_passwd': 'R2L',\n",
        "        'imap': 'R2L',\n",
        "        'multihop': 'R2L',\n",
        "        'phf': 'R2L',\n",
        "        'spy': 'R2L',\n",
        "        'warezclient': 'R2L',\n",
        "        'warezmaster': 'R2L',\n",
        "        'sendmail': 'R2L',\n",
        "        'named': 'R2L',\n",
        "        'snmpgetattack': 'R2L',\n",
        "        'snmpguess': 'R2L',\n",
        "        'xlock': 'R2L',\n",
        "        'xsnoop': 'R2L',\n",
        "        'worm': 'R2L',\n",
        "\n",
        "        'buffer_overflow': 'U2R',\n",
        "        'loadmodule': 'U2R',\n",
        "        'perl': 'U2R',\n",
        "        'rootkit': 'U2R',\n",
        "        'httptunnel': 'U2R',\n",
        "        'ps': 'U2R',\n",
        "        'sqlattack': 'U2R',\n",
        "        'xterm': 'U2R'\n",
        "}\n",
        "\n",
        "\n",
        "is_attack = {\n",
        "        \"DoS\":\"attack\",\n",
        "        \"R2L\":\"attack\",\n",
        "        \"U2R\":\"attack\",\n",
        "        \"Probe\":\"attack\",\n",
        "        \"normal\":\"normal\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGOylNjmPjLw"
      },
      "outputs": [],
      "source": [
        "class read_data:\n",
        "    col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
        "        \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
        "        \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "        \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
        "        \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "        \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "        \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "        \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "        \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "        \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"label\", \"difficulty_level\"]\n",
        "\n",
        "    KDDTrain = pd.read_csv(\"KDDTrain+.txt\",names = col_names,)\n",
        "    KDDTest = pd.read_csv(\"KDDTest+.txt\",names = col_names,)\n",
        "\n",
        "\n",
        "    KDDAll = pd.concat([KDDTrain, KDDTest])\n",
        "\n",
        "    kdd_diff_level_all = KDDAll[\"difficulty_level\"].copy()\n",
        "    kdd_diff_level_train = KDDTrain[\"difficulty_level\"].copy()\n",
        "    kdd_diff_level_test = KDDTest[\"difficulty_level\"].copy()\n",
        "\n",
        "    KDDAll = KDDAll.drop(\"difficulty_level\", axis = 1)\n",
        "\n",
        "    KDDTrain.to_csv(\"KDDAll+.csv\")\n",
        "\n",
        "    KDDTrain_len = KDDTrain.shape[0]\n",
        "    KDDTest_len = KDDTest.shape[0]\n",
        "\n",
        "    KDDAll[\"type\"] = KDDAll.label.map(lambda x: attack_types[x])\n",
        "    KDDAll[\"isa\"] = KDDAll.type.map(lambda x: is_attack[x])\n",
        "\n",
        "    KDDTrain[\"type\"] = KDDTrain.label.map(lambda x: attack_types[x])\n",
        "    KDDTrain[\"isa\"] = KDDTrain.type.map(lambda x: is_attack[x])\n",
        "\n",
        "    KDDTest[\"type\"] = KDDTest.label.map(lambda x: attack_types[x])\n",
        "    KDDTest[\"isa\"] = KDDTest.type.map(lambda x: is_attack[x])\n",
        "\n",
        "    kdd_attack_type_group = KDDAll.groupby(\"type\")\n",
        "    kdd_is_attack_group = KDDAll.groupby(\"isa\")\n",
        "\n",
        "    kdd_attack_type_group.type.count()\n",
        "    kdd_is_attack_group[\"isa\"].count()\n",
        "\n",
        "    KDDAll_is = KDDAll.copy()\n",
        "    KDDAll_type = KDDAll.copy()\n",
        "\n",
        "    KDDAll_is_y = KDDAll[\"isa\"].copy()\n",
        "    KDDAll_is.drop([\"label\", \"isa\"], axis=1, inplace=True)\n",
        "    KDDAll_type_y = KDDAll[\"type\"].copy()\n",
        "    KDDAll_type.drop([\"label\", \"type\"], axis=1, inplace=True)\n",
        "\n",
        "    KDDTrain_is_y = KDDTrain[\"isa\"].copy()\n",
        "    KDDTrain_type_y = KDDTrain[\"type\"].copy()\n",
        "\n",
        "    KDDTest_is_y = KDDTest[\"isa\"].copy()\n",
        "    KDDTest_type_y = KDDTest[\"type\"].copy()\n",
        "\n",
        "    class_mapping = {'attack': 0, 'normal': 1}\n",
        "\n",
        "    Y_Train = KDDTrain_is_y.map(class_mapping)\n",
        "    Y_Test = KDDTest_is_y.map(class_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rbke3BJlPjLw"
      },
      "outputs": [],
      "source": [
        "class preprocess_data:\n",
        "\n",
        "    col_names_onehot = [\"protocol_type\",\"service\",\"flag\",\"type\"]\n",
        "    col_names_onehot_s = [\"protocol_type\",\"service\",\"flag\",\"type\"]\n",
        "    KDDAll_num = read_data.KDDAll_is.drop(col_names_onehot, axis=1)  #pd\n",
        "    KDDAll_onehot_s = read_data.KDDAll_is[ col_names_onehot_s]  #pd\n",
        "\n",
        "    num_pipeline = Pipeline([('scaling', StandardScaler())])\n",
        "    cat_string_pipeline = Pipeline([('imputer', SimpleImputer(strategy = \"constant\", fill_value = \"missing\")), ('ordi', OrdinalEncoder()), ('onehots', OneHotEncoder(categories='auto'))])\n",
        "\n",
        "    num_attribs = list(KDDAll_num)\n",
        "    cat_s_attribs = list(KDDAll_onehot_s)\n",
        "\n",
        "    full_pipeline = ColumnTransformer([(\"num\", num_pipeline, num_attribs), (\"cats\", cat_string_pipeline, cat_s_attribs)])\n",
        "\n",
        "    KDDAll_t = full_pipeline.fit_transform(read_data.KDDAll_is)\n",
        "\n",
        "    X_Train_i = KDDAll_t[:read_data.KDDTrain_len]\n",
        "    X_Test_i = KDDAll_t[read_data.KDDTrain_len:read_data.KDDTrain_len + read_data.KDDTest_len]\n",
        "\n",
        "    X_Train = np.expand_dims(X_Train_i, axis=1)\n",
        "    X_Test = np.expand_dims(X_Test_i, axis=1)\n",
        "    Y_Train = read_data.Y_Train\n",
        "    Y_Test = read_data.Y_Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jGF-uq1PjLx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from scikeras import wrappers\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import losses\n",
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex6J8doiPjLx",
        "outputId": "b426030b-23ac-4a86-924a-5f692078d607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
            "127\n"
          ]
        }
      ],
      "source": [
        "input_dim = preprocess_data.X_Train.shape[2]\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "print(input_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGkYi2uDPjLx"
      },
      "outputs": [],
      "source": [
        "classes = 2\n",
        "loop_back =1\n",
        "hidden_encoder_dim = input_dim\n",
        "hidden_decoder_dim = input_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSGlaEBtPjLy"
      },
      "outputs": [],
      "source": [
        "def build_model(lr, hidden_layers, initiali):\n",
        "    model = models.Sequential([\n",
        "        layers.LSTM(hidden_layers, input_shape=(loop_back, input_dim)),\n",
        "        layers.Dense(1)])\n",
        "    adamopt = optimizers.Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=adamopt)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uj1cARGbPjLy"
      },
      "outputs": [],
      "source": [
        "keras_reg = KerasClassifier(build_model)\n",
        "\n",
        "param_distribs = {\"lr\": reciprocal(0.0001, 0.0005), \"units\": [1, 2, 4]}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, cv=5, scoring='accuracy', n_jobs=-1, error_score='raise')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSayp_BlPjLy"
      },
      "outputs": [],
      "source": [
        "X_Train = preprocess_data.X_Train\n",
        "Y_Train = read_data.Y_Train\n",
        "\n",
        "X_Test = preprocess_data.X_Test\n",
        "Y_Test = read_data.Y_Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjdo0jkYPjLy"
      },
      "outputs": [],
      "source": [
        "batch_s = 2000\n",
        "epoches = 250\n",
        "ver = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM5MSefHPjLz"
      },
      "outputs": [],
      "source": [
        "rnd_search_cv.fit(X_Train, Y_Train, batch_size=batch_s, epochs=epoches, verbose=ver)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_Train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNlyW0jlBQAp",
        "outputId": "6953787d-32b6-487d-a8b1-1889a75fab96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.11248106 -0.00734564 -0.00461423 ...  0.          0.\n",
            "    1.        ]]\n",
            "\n",
            " [[-0.11248106 -0.00740942 -0.00461423 ...  0.          0.\n",
            "    1.        ]]\n",
            "\n",
            " [[-0.11248106 -0.00743641 -0.00461423 ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.11248106 -0.00702399 -0.00451054 ...  0.          0.\n",
            "    1.        ]]\n",
            "\n",
            " [[-0.11248106 -0.00743641 -0.00461423 ...  0.          0.\n",
            "    0.        ]]\n",
            "\n",
            " [[-0.11248106 -0.0074085  -0.00461423 ...  0.          0.\n",
            "    1.        ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(units=1, initiali='uniform', loop_back=10, input_dim=5):\n",
        "    model = models.Sequential()\n",
        "\n",
        "    model.add(layers.LSTM(units, input_shape=(loop_back, input_dim)))\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    adamopt = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=adamopt)\n",
        "    return model\n",
        "\n",
        "keras_reg = KerasClassifier(build_fn=build_model, units=1)\n",
        "\n",
        "param_distribs = {\"units\": [1, 2, 4]}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, cv=5, scoring='accuracy', n_jobs=-1, error_score='raise')\n",
        "\n",
        "X_Train = preprocess_data.X_Train\n",
        "Y_Train = read_data.Y_Train\n",
        "\n",
        "X_Test = preprocess_data.X_Test\n",
        "Y_Test = read_data.Y_Test\n",
        "\n",
        "batch_s = 2000\n",
        "epoches = 250\n",
        "ver = 2\n",
        "rnd_search_cv.fit(X_Train, Y_Train, batch_size=batch_s, epochs=epoches, verbose=ver)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nmg7EPb677ut",
        "outputId": "f51e505c-c9f0-47ed-fd6d-654658b59c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 589, in __call__\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 589, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n    return self.function(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 1491, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 760, in fit\n    self._fit(\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 928, in _fit\n    self._fit_keras_model(\n  File \"/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\", line 524, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_filel_zd9j73.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10, 5), found shape=(None, 1, 127)\n\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-f797c894d6aa>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mepoches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mrnd_search_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1769\u001b[0m             ParameterSampler(\n\u001b[1;32m   1770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1699\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1732\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10, 5), found shape=(None, 1, 127)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ5L-oegPjLz"
      },
      "source": [
        "# NAD on EPC: Model is already pre-trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L_9VJvsPjL0"
      },
      "source": [
        "Model : RNN LSTM Network with 4 hidden layers, Adam optimizer and binary-crossentropy loss function -\n",
        "Epochs: 250 -\n",
        "Batch size : 2000 connections per step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JqbHHhQPjL0"
      },
      "source": [
        "## Start Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVy6uZYTPjL0"
      },
      "outputs": [],
      "source": [
        "pred_test = rnd_search_cv.predict(X_Test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK3_-ZODPjL0"
      },
      "source": [
        "Classification report ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "onPwyzmkPjL0"
      },
      "outputs": [],
      "source": [
        "print(\"Classclassification_report:               \\n\", classification_report(Y_Test, pred_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpP6stD0PjL0"
      },
      "outputs": [],
      "source": [
        "print(\"Best estimator: \\n\", rnd_search_cv.best_estimator_)\n",
        "print(\"Best score: \\n\", rnd_search_cv.best_score_)\n",
        "print(\"Best params: \\n\", rnd_search_cv.best_params_)\n",
        "print(\"Refit time: \\n\", rnd_search_cv.refit_time_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0HVeDk3PjL1"
      },
      "source": [
        "Plot Confusion Matrix Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYXDu8kJPjL1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(Y_Test, pred_test)\n",
        "import itertools\n",
        "classes = ['attack','normal']\n",
        "plt.figure()\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "print(cm)\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j].round(4),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfSQVcD8PjL1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}